{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17828e44",
   "metadata": {},
   "source": [
    "## Описание датасета\n",
    "\n",
    "В работе используется объединённый датасет по публичным российским компаниям, который сочетает рыночные данные (цены акций, капитализация, биржевые мультипликаторы), фундаментальные показатели из T-Invest API и бухгалтерскую финансовую отчётность за 2024 год из базы СПАРК."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720adb25",
   "metadata": {},
   "source": [
    "### Получение списка торгуемых акций (MOEX) через T-Invest API\n",
    "\n",
    "В этом шаге мы выгружаем базовый список акций, доступных для торговли, отфильтровывая рублевые обыкновенные акции (без привилегированных), и сохраняем ключевые идентификаторы компаний в CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f31d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SANDBOX_TOKEN = os.getenv(\"SANDBOX_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:t_tech.invest.logging:dfe09614bca18e57b2f8f7a35b8061d9 Shares\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 151 rows to shares_rub_common.csv\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import csv\n",
    "from t_tech.invest import Client, InstrumentStatus\n",
    "\n",
    "TOKEN = SANDBOX_TOKEN\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "OUT_FILE = \"shares_rub_common.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "with Client(TOKEN) as client:\n",
    "    resp = client.instruments.shares(\n",
    "        instrument_status=InstrumentStatus.INSTRUMENT_STATUS_BASE,\n",
    "        instrument_exchange=InstrumentStatus.INSTRUMENT_STATUS_UNSPECIFIED,\n",
    "    )\n",
    "\n",
    "    for s in resp.instruments:\n",
    "        if s.currency == \"rub\" and \"привил\" not in s.name.lower():\n",
    "            rows.append({\n",
    "                \"figi\": s.figi,\n",
    "                \"ticker\": s.ticker,\n",
    "                \"name\": s.name,\n",
    "                \"issue_size\": s.issue_size,\n",
    "                \"uid\": s.uid,\n",
    "                \"assetUid\": s.asset_uid,\n",
    "            })\n",
    "\n",
    "with open(OUT_FILE, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"figi\", \"ticker\", \"name\", \"issue_size\", \"currency\", \"uid\", \"assetUid\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved {len(rows)} rows to {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cf838",
   "metadata": {},
   "source": [
    "### Загрузка дневных котировок по всем акциям и сохранение в отдельные файлы\n",
    "\n",
    "На этом этапе для каждой акции из списка загружаются дневные свечи за последний год через T-Invest API, после чего данные сохраняются в отдельные CSV-файлы (по одной компании).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba763cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "from t_tech.invest import CandleInterval, Client\n",
    "from t_tech.invest.caching.market_data_cache.cache import MarketDataCache\n",
    "from t_tech.invest.caching.market_data_cache.cache_settings import MarketDataCacheSettings\n",
    "from t_tech.invest.utils import now\n",
    "\n",
    "TOKEN = SANDBOX_TOKEN  \n",
    "logging.basicConfig(format=\"%(levelname)s: %(message)s\", level=logging.FATAL)\n",
    "\n",
    "INPUT_CSV = \"shares_rub_common.csv\"  \n",
    "OUT_DIR = Path(\"stocks\")\n",
    "CACHE_DIR = Path(\"market_data_cache\")\n",
    "\n",
    "DAYS = 365 * 3\n",
    "INTERVAL = CandleInterval.CANDLE_INTERVAL_DAY\n",
    "\n",
    "\n",
    "def safe_filename(s):\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[<>:\"/\\\\|?*\\x00-\\x1F]', \"_\", s) \n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s[:150] if len(s) > 150 else s\n",
    "\n",
    "\n",
    "def q_to_float(q):\n",
    "    if q is None:\n",
    "        return None\n",
    "    try:\n",
    "        return float(q.units) + float(q.nano) / 1_000_000_000\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_figis_from_csv(path):\n",
    "    items = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            figi = (row.get(\"figi\") or \"\").strip()\n",
    "            ticker = (row.get(\"ticker\") or \"\").strip()\n",
    "            name = (row.get(\"name\") or \"\").strip()\n",
    "            if figi:\n",
    "                items.append((figi, ticker, name))\n",
    "    return items\n",
    "\n",
    "\n",
    "def save_candles_for_figi(market_data_cache, figi, out_path):\n",
    "    candles = list(\n",
    "        market_data_cache.get_all_candles(\n",
    "            figi=figi,\n",
    "            from_=now() - timedelta(days=DAYS),\n",
    "            interval=INTERVAL,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"time\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"is_complete\"])\n",
    "        for c in candles:\n",
    "            w.writerow([\n",
    "                c.time.isoformat() if c.time else None,\n",
    "                q_to_float(getattr(c, \"open\", None)),\n",
    "                q_to_float(getattr(c, \"high\", None)),\n",
    "                q_to_float(getattr(c, \"low\", None)),\n",
    "                q_to_float(getattr(c, \"close\", None)),\n",
    "                getattr(c, \"volume\", None),\n",
    "                getattr(c, \"is_complete\", None),\n",
    "            ])\n",
    "\n",
    "    return len(candles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1719a923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "items = read_figis_from_csv(INPUT_CSV)\n",
    "\n",
    "with Client(TOKEN) as client:\n",
    "    settings = MarketDataCacheSettings(base_cache_dir=CACHE_DIR)\n",
    "    market_data_cache = MarketDataCache(settings=settings, services=client)\n",
    "\n",
    "    ok = 0\n",
    "    for figi, ticker, name in items:\n",
    "        label = ticker or name or figi\n",
    "        fname = safe_filename(f\"{ticker or 'TICKER'}_{figi}.csv\")\n",
    "        out_path = OUT_DIR / fname\n",
    "\n",
    "        try:\n",
    "            n = save_candles_for_figi(market_data_cache, figi, out_path)\n",
    "            logging.info(\"Saved %s candles for %s (%s) -> %s\", n, label, figi, out_path)\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            logging.exception(\"Failed for %s (%s): %s\", label, figi, e)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267f9e8",
   "metadata": {},
   "source": [
    "### Выгрузка фундаментальных показателей для всех компаний\n",
    "\n",
    "На этом шаге мы батчами запрашиваем фундаментальные показатели (мультипликаторы и финансовые метрики) для всех компаний из списка, используя assetUid, и сохраняем результаты в единый CSV-файл.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2a93801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded asset UIDs: 151\n",
      "INFO:t_tech.invest.logging:0d3034df8e37c1cdc857a4767d42b79f GetAssetFundamentals\n",
      "INFO:root:Fetched fundamentals: +50 (total 50)\n",
      "INFO:t_tech.invest.logging:9e65a0e049156ad4dcf0ddb92288d0fc GetAssetFundamentals\n",
      "INFO:root:Fetched fundamentals: +49 (total 99)\n",
      "INFO:t_tech.invest.logging:efe53df0b508aaea049ec8a4229ff65d GetAssetFundamentals\n",
      "INFO:root:Fetched fundamentals: +48 (total 147)\n",
      "INFO:t_tech.invest.logging:3490b8114fd5fea4b5c90faa63d7caca GetAssetFundamentals\n",
      "INFO:root:Fetched fundamentals: +1 (total 148)\n",
      "INFO:root:Saved 148 rows to asset_fundamentals_all.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import logging\n",
    "from datetime import date, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from t_tech.invest import Client, GetAssetFundamentalsRequest\n",
    "\n",
    "TOKEN = SANDBOX_TOKEN\n",
    "logging.basicConfig(format=\"%(levelname)s: %(message)s\", level=logging.INFO)\n",
    "\n",
    "INPUT_CSV = \"shares_rub_common.csv\"\n",
    "OUT_CSV = \"asset_fundamentals_all.csv\"\n",
    "\n",
    "BATCH_SIZE = 50 \n",
    "\n",
    "\n",
    "def iso(v):\n",
    "    if isinstance(v, (datetime, date)):\n",
    "        return v.isoformat()\n",
    "    return v\n",
    "\n",
    "\n",
    "def read_asset_uids(path):\n",
    "    uids = []\n",
    "    with open(path, \"r\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "\n",
    "        possible_cols = [\"assetUid\", \"asset_uid\", \"uid\"]\n",
    "        cols = r.fieldnames or []\n",
    "        col = next((c for c in possible_cols if c in cols), None)\n",
    "        if not col:\n",
    "            pass\n",
    "\n",
    "        for row in r:\n",
    "            uid = (row.get(col) or \"\").strip()\n",
    "            if uid:\n",
    "                uids.append(uid)\n",
    "\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for u in uids:\n",
    "        if u not in seen:\n",
    "            seen.add(u)\n",
    "            out.append(u)\n",
    "    return out\n",
    "\n",
    "\n",
    "def obj_to_row(obj):\n",
    "    d = {}\n",
    "    for k, v in vars(obj).items():\n",
    "        d[k] = iso(v)\n",
    "    return d\n",
    "\n",
    "\n",
    "def chunked(xs, n):\n",
    "    for i in range(0, len(xs), n):\n",
    "        yield xs[i:i + n]\n",
    "\n",
    "\n",
    "asset_uids = read_asset_uids(INPUT_CSV)\n",
    "logging.info(\"Loaded asset UIDs: %d\", len(asset_uids))\n",
    "\n",
    "all_rows = []\n",
    "with Client(TOKEN) as client:\n",
    "    for batch in chunked(asset_uids, BATCH_SIZE):\n",
    "        resp = client.instruments.get_asset_fundamentals(GetAssetFundamentalsRequest(assets=batch))\n",
    "\n",
    "        for f in resp.fundamentals:\n",
    "            all_rows.append(obj_to_row(f))\n",
    "\n",
    "        logging.info(\"Fetched fundamentals: +%d (total %d)\", len(resp.fundamentals), len(all_rows))\n",
    "\n",
    "fieldnames = sorted({k for row in all_rows for k in row.keys()})\n",
    "\n",
    "with open(OUT_CSV, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    w.writerows(all_rows)\n",
    "\n",
    "logging.info(\"Saved %d rows to %s\", len(all_rows), OUT_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a2cc2",
   "metadata": {},
   "source": [
    "### Формирование сводной таблицы с рыночными и фундаментальными показателями\n",
    "\n",
    "На этом этапе мы объединяем список акций и фундаментальные данные в одну сводную таблицу по asset_uid, упорядочивая ключевые показатели и сохраняя результат в CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e40ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summary table: stocks_summary.csv\n",
      "Rows: 151\n",
      "Columns: 62\n",
      "Missing columns (ok): ['currency']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SHARES_FILE = \"shares_rub_common.csv\"\n",
    "FUND_FILE = \"asset_fundamentals_all.csv\"\n",
    "OUT_FILE = \"stocks_summary.csv\"\n",
    "\n",
    "\n",
    "shares = pd.read_csv(SHARES_FILE, encoding=\"utf-8-sig\")\n",
    "funds = pd.read_csv(FUND_FILE, encoding=\"utf-8-sig\")\n",
    "\n",
    "shares = shares.rename(columns={\"assetUid\": \"asset_uid\"})\n",
    "\n",
    "df = shares.merge(\n",
    "    funds,\n",
    "    how=\"left\",\n",
    "    on=\"asset_uid\",\n",
    ")\n",
    "\n",
    "preferred_cols = [\n",
    "    \"figi\",\n",
    "    \"ticker\",\n",
    "    \"name\",\n",
    "    \"asset_uid\",\n",
    "    \"issue_size\",\n",
    "    \"shares_outstanding\",\n",
    "    \"free_float\",\n",
    "    \"market_capitalization\",\n",
    "    \"pe_ratio_ttm\",\n",
    "    \"price_to_book_ttm\",\n",
    "    \"price_to_sales_ttm\",\n",
    "    \"roe\",\n",
    "    \"roa\",\n",
    "    \"net_margin_mrq\",\n",
    "    \"revenue_ttm\",\n",
    "    \"net_income_ttm\",\n",
    "    \"total_debt_mrq\",\n",
    "    \"total_debt_to_equity_mrq\",\n",
    "    \"average_daily_volume_last_10_days\",\n",
    "    \"average_daily_volume_last_4_weeks\",\n",
    "    \"high_price_last_52_weeks\",\n",
    "    \"low_price_last_52_weeks\",\n",
    "    \"currency\",\n",
    "]\n",
    "\n",
    "first_cols = [c for c in preferred_cols if c in df.columns]\n",
    "\n",
    "rest_cols = [c for c in df.columns if c not in first_cols]\n",
    "\n",
    "df = df[first_cols + rest_cols]\n",
    "\n",
    "df.to_csv(OUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved summary table:\", OUT_FILE)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "\n",
    "missing = [c for c in preferred_cols if c not in df.columns]\n",
    "if missing:\n",
    "    print(\"Missing columns (ok):\", missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1100a1",
   "metadata": {},
   "source": [
    "### Объединение рыночных данных с бухгалтерской отчетностью СПАРК\n",
    "\n",
    "На этом шаге сводная таблица с рыночными и фундаментальными показателями объединяется с финансовой отчетностью из СПАРКа по биржевому тикеру, при этом сохраняются только компании, присутствующие в обоих источниках, и устраняются дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78da2153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARK duplicate tickers (count):\n",
      "ticker\n",
      "NAN    3779\n",
      "\n",
      "Saved merged table: stocks_summary_with_spark.csv\n",
      "Rows: 91\n",
      "Columns: 154\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "STOCKS_FILE = \"stocks_summary.csv\"\n",
    "SPARK_FILE = \"СПАРК_Выборка_компаний_20260204_1918.xlsx\"\n",
    "OUT_FILE = \"stocks_summary_with_spark.csv\"\n",
    "\n",
    "\n",
    "stocks = pd.read_csv(STOCKS_FILE, encoding=\"utf-8-sig\")\n",
    "spark = pd.read_excel(SPARK_FILE)\n",
    "\n",
    "spark = spark.rename(columns={\"Тикер биржевой\": \"ticker\"})\n",
    "\n",
    "stocks[\"ticker\"] = stocks[\"ticker\"].astype(str).str.strip().str.upper()\n",
    "spark[\"ticker\"] = spark[\"ticker\"].astype(str).str.strip().str.upper()\n",
    "\n",
    "dup = spark[spark[\"ticker\"].duplicated(keep=False)].copy()\n",
    "if len(dup) > 0:\n",
    "    print(\"SPARK duplicate tickers (count):\")\n",
    "    print(dup[\"ticker\"].value_counts().head(30).to_string())\n",
    "    print()\n",
    "\n",
    "sort_cols = []\n",
    "if \"2024, Активы  всего, RUB\" in spark.columns:\n",
    "    sort_cols.append(\"2024, Активы  всего, RUB\")\n",
    "elif \"2024, Выручка, RUB\" in spark.columns:\n",
    "    sort_cols.append(\"2024, Выручка, RUB\")\n",
    "\n",
    "if sort_cols:\n",
    "    spark_sorted = spark.sort_values(sort_cols, ascending=False)\n",
    "    spark_uniq = spark_sorted.drop_duplicates(subset=[\"ticker\"], keep=\"first\")\n",
    "else:\n",
    "    spark_uniq = spark.drop_duplicates(subset=[\"ticker\"], keep=\"first\")\n",
    "\n",
    "stocks_uniq = stocks.drop_duplicates(subset=[\"ticker\"], keep=\"first\")\n",
    "\n",
    "df = stocks_uniq.merge(\n",
    "    spark_uniq,\n",
    "    how=\"inner\",\n",
    "    on=\"ticker\",\n",
    "    suffixes=(\"_api\", \"_spark\"),\n",
    "    validate=\"one_to_one\" \n",
    ")\n",
    "\n",
    "df.to_csv(OUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Saved merged table:\", OUT_FILE)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c97df",
   "metadata": {},
   "source": [
    "### Финальный датасет\n",
    "\n",
    "На этом этапе мы выбираем нужные нам переменные для финального датасета и приводим значения к читаемому формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f41d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: final_dataset.xlsx | rows=91 cols=19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Тикер</th>\n",
       "      <th>Компания</th>\n",
       "      <th>Капитализация, RUB</th>\n",
       "      <th>P/E (TTM)</th>\n",
       "      <th>P/B (TTM)</th>\n",
       "      <th>P/S (TTM)</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>Чистая маржа (MRQ)</th>\n",
       "      <th>Бета</th>\n",
       "      <th>Free-float</th>\n",
       "      <th>Средн. дневной объём (4 недели)</th>\n",
       "      <th>ИНН</th>\n",
       "      <th>Ср. численность 2024</th>\n",
       "      <th>Выручка 2024, RUB</th>\n",
       "      <th>Чистая прибыль 2024, RUB</th>\n",
       "      <th>Активы 2024, RUB</th>\n",
       "      <th>Капитал и резервы 2024, RUB</th>\n",
       "      <th>Совокупный долг 2024, RUB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VSMO</td>\n",
       "      <td>ВСМПО-АВИСМА</td>\n",
       "      <td>3.611051e+11</td>\n",
       "      <td>52.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.26</td>\n",
       "      <td>1.46</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.285360e+03</td>\n",
       "      <td>6.607001e+09</td>\n",
       "      <td>13486.0</td>\n",
       "      <td>1.010067e+11</td>\n",
       "      <td>1.003488e+10</td>\n",
       "      <td>4.662586e+11</td>\n",
       "      <td>2.736734e+11</td>\n",
       "      <td>1.925853e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNAC</td>\n",
       "      <td>Объединенная авиастроительная корпорация</td>\n",
       "      <td>4.860102e+11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-15.40</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.778768e+08</td>\n",
       "      <td>7.708619e+09</td>\n",
       "      <td>33340.0</td>\n",
       "      <td>1.980137e+11</td>\n",
       "      <td>-2.412211e+10</td>\n",
       "      <td>1.862248e+12</td>\n",
       "      <td>3.292258e+11</td>\n",
       "      <td>1.533022e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGNT</td>\n",
       "      <td>Магнит</td>\n",
       "      <td>3.236705e+11</td>\n",
       "      <td>11.97</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.640095e+05</td>\n",
       "      <td>2.309086e+09</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4.120620e+08</td>\n",
       "      <td>6.377790e+10</td>\n",
       "      <td>3.077855e+11</td>\n",
       "      <td>2.081270e+11</td>\n",
       "      <td>9.965849e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KZIZ</td>\n",
       "      <td>Красногорский завод им. С.А. Зверева - ао</td>\n",
       "      <td>1.568798e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-17.79</td>\n",
       "      <td>-3.15</td>\n",
       "      <td>-7.03</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.875800e+02</td>\n",
       "      <td>5.024023e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.881731e+10</td>\n",
       "      <td>3.247110e+08</td>\n",
       "      <td>4.907697e+10</td>\n",
       "      <td>7.375392e+09</td>\n",
       "      <td>4.170158e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELG</td>\n",
       "      <td>Селигдар</td>\n",
       "      <td>5.983270e+10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-64.10</td>\n",
       "      <td>-5.67</td>\n",
       "      <td>-13.30</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3.236956e+07</td>\n",
       "      <td>1.402047e+09</td>\n",
       "      <td>241.0</td>\n",
       "      <td>1.173288e+09</td>\n",
       "      <td>6.420100e+07</td>\n",
       "      <td>1.175407e+11</td>\n",
       "      <td>3.076840e+10</td>\n",
       "      <td>8.677229e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Тикер                                   Компания  Капитализация, RUB  \\\n",
       "0  VSMO                               ВСМПО-АВИСМА        3.611051e+11   \n",
       "1  UNAC   Объединенная авиастроительная корпорация        4.860102e+11   \n",
       "2  MGNT                                     Магнит        3.236705e+11   \n",
       "3  KZIZ  Красногорский завод им. С.А. Зверева - ао        1.568798e+09   \n",
       "4  SELG                                   Селигдар        5.983270e+10   \n",
       "\n",
       "   P/E (TTM)  P/B (TTM)  P/S (TTM)    ROE   ROA  Чистая маржа (MRQ)  Бета  \\\n",
       "0      52.42       1.20       3.34   2.26  1.46                6.36  1.00   \n",
       "1       0.00       4.89       0.81 -15.40 -0.54               -2.06  0.56   \n",
       "2      11.97       1.76       0.10  15.68  1.75                0.83  0.61   \n",
       "3       0.00       0.18       0.07 -17.79 -3.15               -7.03  0.56   \n",
       "4       0.00       4.30       0.77 -64.10 -5.67              -13.30  0.58   \n",
       "\n",
       "   Free-float  Средн. дневной объём (4 недели)           ИНН  \\\n",
       "0        0.10                     1.285360e+03  6.607001e+09   \n",
       "1        0.03                     1.778768e+08  7.708619e+09   \n",
       "2        0.67                     2.640095e+05  2.309086e+09   \n",
       "3        0.00                     3.875800e+02  5.024023e+09   \n",
       "4        0.25                     3.236956e+07  1.402047e+09   \n",
       "\n",
       "   Ср. численность 2024  Выручка 2024, RUB  Чистая прибыль 2024, RUB  \\\n",
       "0               13486.0       1.010067e+11              1.003488e+10   \n",
       "1               33340.0       1.980137e+11             -2.412211e+10   \n",
       "2                4500.0       4.120620e+08              6.377790e+10   \n",
       "3                   NaN       1.881731e+10              3.247110e+08   \n",
       "4                 241.0       1.173288e+09              6.420100e+07   \n",
       "\n",
       "   Активы 2024, RUB  Капитал и резервы 2024, RUB  Совокупный долг 2024, RUB  \n",
       "0      4.662586e+11                 2.736734e+11               1.925853e+11  \n",
       "1      1.862248e+12                 3.292258e+11               1.533022e+12  \n",
       "2      3.077855e+11                 2.081270e+11               9.965849e+10  \n",
       "3      4.907697e+10                 7.375392e+09               4.170158e+10  \n",
       "4      1.175407e+11                 3.076840e+10               8.677229e+10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "IN_FILE = Path(\"stocks_summary_with_spark.csv\")  \n",
    "OUT_XLSX = Path(\"final_dataset.xlsx\")\n",
    "\n",
    "df = pd.read_csv(IN_FILE, encoding=\"utf-8-sig\")\n",
    "\n",
    "df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "important_cols = [\n",
    "    \"ticker\", \"name\",\n",
    "\n",
    "    \"last_close\", \"last_close_time\",\n",
    "    \"market_capitalization\",\n",
    "    \"pe_ratio_ttm\", \"price_to_book_ttm\", \"price_to_sales_ttm\",\n",
    "    \"roe\", \"roa\", \"net_margin_mrq\",\n",
    "    \"beta\", \"free_float\",\n",
    "    \"average_daily_volume_last_4_weeks\",\n",
    "\n",
    "    \"Код налогоплательщика\",\n",
    "    \"2024, Среднесписочная численность работников\",\n",
    "\n",
    "    \"2024, Выручка, RUB\",\n",
    "    \"2024, Чистая прибыль (убыток), RUB\",\n",
    "    \"2024, Активы  всего, RUB\",\n",
    "    \"2024, Капитал и резервы, RUB\",\n",
    "    \"2024, Совокупный долг, RUB\",\n",
    "]\n",
    "\n",
    "keep = [c for c in important_cols if c in df.columns]\n",
    "df = df[keep].copy()\n",
    "\n",
    "num_candidates = [\n",
    "    \"last_close\", \"market_capitalization\",\n",
    "    \"pe_ratio_ttm\", \"price_to_book_ttm\", \"price_to_sales_ttm\",\n",
    "    \"roe\", \"roa\", \"net_margin_mrq\",\n",
    "    \"beta\", \"free_float\", \"average_daily_volume_last_4_weeks\",\n",
    "    \"2024, Среднесписочная численность работников\",\n",
    "    \"2024, Выручка, RUB\",\n",
    "    \"2024, Чистая прибыль (убыток), RUB\",\n",
    "    \"2024, Активы  всего, RUB\",\n",
    "    \"2024, Капитал и резервы, RUB\",\n",
    "    \"2024, Совокупный долг, RUB\",\n",
    "]\n",
    "for c in num_candidates:\n",
    "    if c in df.columns:\n",
    "        df[c] = (\n",
    "            df[c].astype(str)\n",
    "            .str.replace(\"\\u00A0\", \"\", regex=False)  \n",
    "            .str.replace(\" \", \"\", regex=False)\n",
    "            .str.replace(\",\", \".\", regex=False)\n",
    "        )\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "date_cols = [c for c in [\"last_close_time\"] if c in df.columns]\n",
    "for c in date_cols:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True).dt.strftime(\"%Y-%m\")\n",
    "\n",
    "rename_map = {\n",
    "    \"ticker\": \"Тикер\",\n",
    "    \"name\": \"Компания\",\n",
    "    \"last_close\": \"Цена закрытия (последняя), RUB\",\n",
    "    \"last_close_time\": \"Период (YYYY-MM)\",\n",
    "    \"market_capitalization\": \"Капитализация, RUB\",\n",
    "    \"pe_ratio_ttm\": \"P/E (TTM)\",\n",
    "    \"price_to_book_ttm\": \"P/B (TTM)\",\n",
    "    \"price_to_sales_ttm\": \"P/S (TTM)\",\n",
    "    \"roe\": \"ROE\",\n",
    "    \"roa\": \"ROA\",\n",
    "    \"net_margin_mrq\": \"Чистая маржа (MRQ)\",\n",
    "    \"beta\": \"Бета\",\n",
    "    \"free_float\": \"Free-float\",\n",
    "    \"average_daily_volume_last_4_weeks\": \"Средн. дневной объём (4 недели)\",\n",
    "    \"Код налогоплательщика\": \"ИНН\",\n",
    "    \"2024, Среднесписочная численность работников\": \"Ср. численность 2024\",\n",
    "    \"2024, Выручка, RUB\": \"Выручка 2024, RUB\",\n",
    "    \"2024, Чистая прибыль (убыток), RUB\": \"Чистая прибыль 2024, RUB\",\n",
    "    \"2024, Активы  всего, RUB\": \"Активы 2024, RUB\",\n",
    "    \"2024, Капитал и резервы, RUB\": \"Капитал и резервы 2024, RUB\",\n",
    "    \"2024, Совокупный долг, RUB\": \"Совокупный долг 2024, RUB\",\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "with pd.ExcelWriter(OUT_XLSX, engine=\"openpyxl\") as writer:\n",
    "    df.to_excel(writer, index=False, sheet_name=\"dataset\")\n",
    "\n",
    "print(f\"Saved: {OUT_XLSX} | rows={len(df)} cols={len(df.columns)}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68316c1",
   "metadata": {},
   "source": [
    "### Парсинг новостей с Финам для дальнейшего текстового анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9b8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VSMO] saved 50 -> parsed_news\\VSMO_finam_publications.csv\n",
      "[UNAC] saved 50 -> parsed_news\\UNAC_finam_publications.csv\n",
      "[MGNT] saved 50 -> parsed_news\\MGNT_finam_publications.csv\n",
      "[KZIZ] saved 1 -> parsed_news\\KZIZ_finam_publications.csv\n",
      "[SELG] saved 50 -> parsed_news\\SELG_finam_publications.csv\n",
      "[SLAV] saved 4 -> parsed_news\\SLAV_finam_publications.csv\n",
      "[PRFN] saved 48 -> parsed_news\\PRFN_finam_publications.csv\n",
      "[NKHP] saved 50 -> parsed_news\\NKHP_finam_publications.csv\n",
      "[TGKJ] saved 50 -> parsed_news\\TGKJ_finam_publications.csv\n",
      "[ALRS] saved 50 -> parsed_news\\ALRS_finam_publications.csv\n",
      "[TATN] saved 50 -> parsed_news\\TATN_finam_publications.csv\n",
      "[GRNT] saved 50 -> parsed_news\\GRNT_finam_publications.csv\n",
      "[RTKM] saved 50 -> parsed_news\\RTKM_finam_publications.csv\n",
      "[TGKN] saved 50 -> parsed_news\\TGKN_finam_publications.csv\n",
      "[GCHE] saved 50 -> parsed_news\\GCHE_finam_publications.csv\n",
      "[UWGN] saved 50 -> parsed_news\\UWGN_finam_publications.csv\n",
      "[NKNC] saved 50 -> parsed_news\\NKNC_finam_publications.csv\n",
      "[VRSB] saved 50 -> parsed_news\\VRSB_finam_publications.csv\n",
      "[NOMP] saved 22 -> parsed_news\\NOMP_finam_publications.csv\n",
      "[SNGS] saved 50 -> parsed_news\\SNGS_finam_publications.csv\n",
      "[PIKK] saved 50 -> parsed_news\\PIKK_finam_publications.csv\n",
      "[ROSN] saved 50 -> parsed_news\\ROSN_finam_publications.csv\n",
      "[MRKU] saved 50 -> parsed_news\\MRKU_finam_publications.csv\n",
      "[MRKV] saved 50 -> parsed_news\\MRKV_finam_publications.csv\n",
      "[CNTL] saved 50 -> parsed_news\\CNTL_finam_publications.csv\n",
      "[SVAV] saved 50 -> parsed_news\\SVAV_finam_publications.csv\n",
      "[KMAZ] saved 50 -> parsed_news\\KMAZ_finam_publications.csv\n",
      "[KZOS] saved 50 -> parsed_news\\KZOS_finam_publications.csv\n",
      "[SBER] saved 50 -> parsed_news\\SBER_finam_publications.csv\n",
      "[GAZP] saved 50 -> parsed_news\\GAZP_finam_publications.csv\n",
      "[BSPB] saved 50 -> parsed_news\\BSPB_finam_publications.csv\n",
      "[LSNG] saved 50 -> parsed_news\\LSNG_finam_publications.csv\n",
      "[KROT] saved 50 -> parsed_news\\KROT_finam_publications.csv\n",
      "[SIBN] saved 50 -> parsed_news\\SIBN_finam_publications.csv\n",
      "[KLSB] saved 50 -> parsed_news\\KLSB_finam_publications.csv\n",
      "[CHMK] saved 50 -> parsed_news\\CHMK_finam_publications.csv\n",
      "[MRKZ] saved 50 -> parsed_news\\MRKZ_finam_publications.csv\n",
      "[APTK] saved 50 -> parsed_news\\APTK_finam_publications.csv\n",
      "[HYDR] saved 50 -> parsed_news\\HYDR_finam_publications.csv\n",
      "[RASP] saved 50 -> parsed_news\\RASP_finam_publications.csv\n",
      "[GMKN] saved 50 -> parsed_news\\GMKN_finam_publications.csv\n",
      "[UPRO] saved 50 -> parsed_news\\UPRO_finam_publications.csv\n",
      "[MSNG] saved 50 -> parsed_news\\MSNG_finam_publications.csv\n",
      "[AFKS] saved 50 -> parsed_news\\AFKS_finam_publications.csv\n",
      "[PLZL] saved 50 -> parsed_news\\PLZL_finam_publications.csv\n",
      "[LIFE] saved 50 -> parsed_news\\LIFE_finam_publications.csv\n",
      "[IRKT] saved 50 -> parsed_news\\IRKT_finam_publications.csv\n",
      "[TTLK] saved 50 -> parsed_news\\TTLK_finam_publications.csv\n",
      "[SVCB] saved 50 -> parsed_news\\SVCB_finam_publications.csv\n",
      "[PHOR] saved 50 -> parsed_news\\PHOR_finam_publications.csv\n",
      "[MAGN] saved 50 -> parsed_news\\MAGN_finam_publications.csv\n",
      "[VTBR] saved 50 -> parsed_news\\VTBR_finam_publications.csv\n",
      "[MRKP] saved 50 -> parsed_news\\MRKP_finam_publications.csv\n",
      "[DVEC] saved 50 -> parsed_news\\DVEC_finam_publications.csv\n",
      "[MTSS] saved 50 -> parsed_news\\MTSS_finam_publications.csv\n",
      "[FEES] saved 50 -> parsed_news\\FEES_finam_publications.csv\n",
      "[OBNE] no publications found -> parsed_news\\OBNE_finam_publications.csv\n",
      "[PMSB] saved 50 -> parsed_news\\PMSB_finam_publications.csv\n",
      "[RBCM] saved 50 -> parsed_news\\RBCM_finam_publications.csv\n",
      "[MSRS] saved 50 -> parsed_news\\MSRS_finam_publications.csv\n",
      "[IRAO] saved 50 -> parsed_news\\IRAO_finam_publications.csv\n",
      "[NSVZ] saved 50 -> parsed_news\\NSVZ_finam_publications.csv\n",
      "[BLNG] saved 50 -> parsed_news\\BLNG_finam_publications.csv\n",
      "[NVTK] saved 50 -> parsed_news\\NVTK_finam_publications.csv\n",
      "[UNKL] saved 50 -> parsed_news\\UNKL_finam_publications.csv\n",
      "[ROLO] saved 50 -> parsed_news\\ROLO_finam_publications.csv\n",
      "[OGKB] saved 50 -> parsed_news\\OGKB_finam_publications.csv\n",
      "[CBOM] saved 50 -> parsed_news\\CBOM_finam_publications.csv\n",
      "[ABRD] saved 50 -> parsed_news\\ABRD_finam_publications.csv\n",
      "[TRMK] saved 50 -> parsed_news\\TRMK_finam_publications.csv\n",
      "[CHMF] saved 50 -> parsed_news\\CHMF_finam_publications.csv\n",
      "[LSRG] saved 50 -> parsed_news\\LSRG_finam_publications.csv\n",
      "[BANE] saved 50 -> parsed_news\\BANE_finam_publications.csv\n",
      "[AFLT] saved 50 -> parsed_news\\AFLT_finam_publications.csv\n",
      "[MVID] saved 50 -> parsed_news\\MVID_finam_publications.csv\n",
      "[MSTT] saved 50 -> parsed_news\\MSTT_finam_publications.csv\n",
      "[MTLR] saved 50 -> parsed_news\\MTLR_finam_publications.csv\n",
      "[AKRN] saved 50 -> parsed_news\\AKRN_finam_publications.csv\n",
      "[RKKE] saved 50 -> parsed_news\\RKKE_finam_publications.csv\n",
      "[MRKC] saved 50 -> parsed_news\\MRKC_finam_publications.csv\n",
      "[KAZT] saved 50 -> parsed_news\\KAZT_finam_publications.csv\n",
      "[YAKG] saved 50 -> parsed_news\\YAKG_finam_publications.csv\n",
      "[TGKB] saved 50 -> parsed_news\\TGKB_finam_publications.csv\n",
      "[NLMK] saved 50 -> parsed_news\\NLMK_finam_publications.csv\n",
      "[FESH] saved 50 -> parsed_news\\FESH_finam_publications.csv\n",
      "[MRKS] saved 50 -> parsed_news\\MRKS_finam_publications.csv\n",
      "[LKOH] saved 50 -> parsed_news\\LKOH_finam_publications.csv\n",
      "[UDMN] saved 19 -> parsed_news\\UDMN_finam_publications.csv\n",
      "[NMTP] saved 50 -> parsed_news\\NMTP_finam_publications.csv\n",
      "[TGKA] saved 50 -> parsed_news\\TGKA_finam_publications.csv\n",
      "[MRKY] saved 50 -> parsed_news\\MRKY_finam_publications.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "STOCKS_FILE = \"stocks_summary_with_spark.csv\"\n",
    "OUT_DIR = Path(\"parsed_news\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE = \"https://www.finam.ru\"\n",
    "URL_TEMPLATE = \"https://www.finam.ru/quote/moex/{ticker}/publications/\"\n",
    "\n",
    "WAIT_SEC = 20\n",
    "SLEEP_BETWEEN_TICKERS = 1.0\n",
    "\n",
    "CLICK_LOAD_MORE_TIMES = 0  \n",
    "\n",
    "\n",
    "def safe_filename(name: str) -> str:\n",
    "    name = (name or \"\").strip()\n",
    "    name = re.sub(r'[<>:\"/\\\\|?*\\x00-\\x1F]', \"_\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    return name[:150] if len(name) > 150 else name\n",
    "\n",
    "\n",
    "RU_MONTHS = {\n",
    "    \"янв\": \"01\", \"фев\": \"02\", \"мар\": \"03\", \"апр\": \"04\", \"май\": \"05\", \"июн\": \"06\",\n",
    "    \"июл\": \"07\", \"авг\": \"08\", \"сен\": \"09\", \"окт\": \"10\", \"ноя\": \"11\", \"дек\": \"12\",\n",
    "}\n",
    "\n",
    "\n",
    "def parse_date(raw: str):\n",
    "    raw = (raw or \"\").strip().lower()\n",
    "\n",
    "    m = re.search(r\"(\\d{2})\\.(\\d{2})\\.(\\d{2,4})\", raw)\n",
    "    if m:\n",
    "        dd, mm, yy = m.group(1), m.group(2), m.group(3)\n",
    "        if len(yy) == 2:\n",
    "            yy = \"20\" + yy\n",
    "        return f\"{yy}-{mm}-{dd}\", f\"{yy}-{mm}\"\n",
    "\n",
    "    m = re.search(r\"(\\d{1,2})\\s+([а-яё]{3,})\\s+(\\d{4})\", raw)\n",
    "    if m:\n",
    "        dd = f\"{int(m.group(1)):02d}\"\n",
    "        mon = m.group(2)[:3]\n",
    "        yy = m.group(3)\n",
    "        mm = RU_MONTHS.get(mon)\n",
    "        if mm:\n",
    "            return f\"{yy}-{mm}-{dd}\", f\"{yy}-{mm}\"\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def parse_publications_from_html(html: str, page_url: str, ticker: str):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    items = []\n",
    "\n",
    "    for node in soup.select('div[data-publication]'):\n",
    "        date_raw = \"\"\n",
    "        date_span = node.select_one(\"div > div > span.font-xs.cl-darkgrey\")\n",
    "        if date_span:\n",
    "            date_raw = date_span.get_text(strip=True)\n",
    "        date_full, date_ym = parse_date(date_raw)\n",
    "\n",
    "        a = node.select_one(\"a.cl-blue.font-l.bold\")\n",
    "        title = a.get_text(strip=True) if a else \"\"\n",
    "        href = a.get(\"href\") if a else \"\"\n",
    "        url = urljoin(BASE, href) if href else \"\"\n",
    "\n",
    "        p = node.select_one(\"p.font-s.cl-black\")\n",
    "        text = p.get_text(\" \", strip=True) if p else \"\"\n",
    "\n",
    "        if not (title or text or url):\n",
    "            continue\n",
    "\n",
    "        items.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"date\": date_full,\n",
    "            \"date_ym\": date_ym,\n",
    "            \"date_raw\": date_raw,\n",
    "            \"title\": title,\n",
    "            \"text\": text,\n",
    "            \"url\": url,\n",
    "            \"source_page\": page_url,\n",
    "        })\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--window-size=1400,900\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/122.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "\n",
    "def click_load_more_if_exists(driver, times: int):\n",
    "    for _ in range(times):\n",
    "        try:\n",
    "            btn = driver.find_element(By.XPATH, \"//button[contains(., 'Показать') or contains(., 'Загрузить')]\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", btn)\n",
    "            time.sleep(0.4)\n",
    "            btn.click()\n",
    "            time.sleep(1.2)\n",
    "        except Exception:\n",
    "            break\n",
    "\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(STOCKS_FILE, encoding=\"utf-8-sig\")\n",
    "    tickers = (\n",
    "        df[\"ticker\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "        .dropna()\n",
    "        .unique()\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    driver = setup_driver()\n",
    "    wait = WebDriverWait(driver, WAIT_SEC)\n",
    "\n",
    "    try:\n",
    "        for t in tickers:\n",
    "            url = URL_TEMPLATE.format(ticker=t.lower())\n",
    "            driver.get(url)\n",
    "\n",
    "            try:\n",
    "                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-publication]\")))\n",
    "            except Exception:\n",
    "                out_file = OUT_DIR / f\"{safe_filename(t)}_finam_publications.csv\"\n",
    "                with open(out_file, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "                    w = csv.DictWriter(\n",
    "                        f,\n",
    "                        fieldnames=[\"ticker\", \"date\", \"date_ym\", \"date_raw\", \"title\", \"text\", \"url\", \"source_page\"]\n",
    "                    )\n",
    "                    w.writeheader()\n",
    "                print(f\"[{t}] no publications found -> {out_file}\")\n",
    "                time.sleep(SLEEP_BETWEEN_TICKERS)\n",
    "                continue\n",
    "\n",
    "            if CLICK_LOAD_MORE_TIMES > 0:\n",
    "                click_load_more_if_exists(driver, CLICK_LOAD_MORE_TIMES)\n",
    "\n",
    "            html = driver.page_source\n",
    "            items = parse_publications_from_html(html, url, t)\n",
    "\n",
    "            out_file = OUT_DIR / f\"{safe_filename(t)}_finam_publications.csv\"\n",
    "            with open(out_file, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
    "                w = csv.DictWriter(\n",
    "                    f,\n",
    "                    fieldnames=[\"ticker\", \"date\", \"date_ym\", \"date_raw\", \"title\", \"text\", \"url\", \"source_page\"]\n",
    "                )\n",
    "                w.writeheader()\n",
    "                w.writerows(items)\n",
    "\n",
    "            print(f\"[{t}] saved {len(items)} -> {out_file}\")\n",
    "            time.sleep(SLEEP_BETWEEN_TICKERS)\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7ea01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
